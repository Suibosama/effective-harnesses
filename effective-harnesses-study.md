# 长时间运行 Agent 框架最佳实践深度学习笔记

> 来源: [Anthropic Engineering Blog - Effective harnesses for long-running agents](https://www.anthropic.com/engineering/effective-harnesses-for-long-running-agents)
> 学习日期: 2026-02-14

## 一、核心问题剖析

### 1.1 长时间运行 Agent 的两大根本挑战

| 挑战 | 描述 | 影响 |
|------|------|------|
| **记忆丧失** | 每次新会话开始时,Agent 没有之前工作的记忆 | 重复工作、无法衔接进度 |
| **失败模式** | Agent 试图一次性完成整个应用,或过早宣布任务完成 | 项目失控、质量不可控 |

### 1.2 个人思考:为什么 Agent 容易"失控"?

Agent 本质上是一个**目标导向的循环系统**,它的核心机制是:
```
理解目标 → 采取行动 → 评估结果 → 调整策略 → 循环
```

问题在于:
1. **目标粒度过粗**: 当用户说"帮我做一个聊天应用"时,Agent 理解的是一个宏大目标,而不是一系列可管理的子任务
2. **自我评估偏差**: Agent 倾向于过度自信,容易在未完成时误判为已完成
3. **上下文耗尽**: 长任务导致上下文窗口膨胀,模型容易"遗忘"早期设定

---

## 二、双轨架构解决方案

### 2.1 初始化 Agent (Initializer Agent)

**职责**: 首次运行时建立项目基础设施

```
创建内容:
├── init.sh          # 启动脚本(启动开发服务器、数据库等)
├── claude-progress.txt  # 进度日志
├── feature_list.json     # 功能清单(初始标记为失败)
└── git commit           # 初始提交
```

**关键洞察**: 初始化 Agent 的核心价值不在于"做事",而在于**建立秩序**。它为后续所有工作奠定了可预测的基础。

### 2.2 编码 Agent (Coding Agent)

**职责**: 增量实现功能,每次只做一个 feature

```
会话流程:
1. 读取 git 日志和进度文件
2. 选择最高优先级未完成的 feature
3. 增量实现该功能
4. 提交 git 并更新进度文件
```

---

## 三、Feature 列表设计

### 3.1 JSON 结构设计

```json
{
  "category": "functional",
  "description": "New chat button creates a fresh conversation",
  "steps": [
    "Navigate to main interface",
    "Click the 'New Chat' button",
    "Verify a new conversation is created"
  ],
  "passes": false
}
```

### 3.2 核心原则(我的解读)

| 原则 | 目的 | 深层原因 |
|------|------|----------|
| **仅修改 passes 字段** | 防止 Agent "偷懒"删除难以实现的测试 | 强制完整实现功能 |
| **禁止删除/修改测试用例** | 保证验收标准一致性 | Agent 可能会为了"方便"而降低标准 |
| **JSON 格式** | 避免模型误改结构 | 结构化数据比自然语言更"安全" |

### 3.3 个人思考:为什么是 JSON 而不是 Markdown?

1. **Token 效率**: JSON 更紧凑,适合长上下文
2. **解析确定性**: JSON 解析不会产生歧义
3. **可编程性**: 脚本处理易于被、自动更新
4. **防篡改**: 格式错误会导致解析失败,提供了一层保护

---

## 四、增量进度策略

### 4.1 核心原则

- **每次只处理一个 feature**: 降低认知复杂度,保证可回滚性
- **保持代码可合并状态**: 无重大 bug、符合代码规范、文档完整
- **使用 git 作为状态机**: 每次会话有明确的起点和终点

### 4.2 增量策略的价值分析

```
传统方式:
目标: 构建完整应用
└── 风险: 中间状态不可用,难以回滚

增量方式:
目标: 完成一个可验证的 feature
└── 优势: 每次提交都是有效的,随时可以回滚
```

### 4.3 我的补充:检查点机制

建议在 feature 级别之外增加**子检查点**:

```json
{
  "feature": "用户登录功能",
  "checkpoints": [
    { "id": "cp1", "desc": "数据库用户表创建", "status": "done" },
    { "id": "cp2", "desc": "登录 API 接口", "status": "in_progress" },
    { "id": "cp3", "desc": "前端登录页面", "status": "pending" }
  ]
}
```

这样可以:
- 提供更细粒度的进度追踪
- 便于在长任务中途暂停和恢复
- 帮助 Agent 更好地评估当前状态

---

## 五、自动化测试集成

### 5.1 Puppeteer MCP 的作用

```python
# 典型的自动化测试流程
async def test_feature(feature):
    # 1. 启动开发服务器
    await start_dev_server()

    # 2. 导航到应用
    await page.goto("http://localhost:3000")

    # 3. 执行 feature 描述的操作
    await perform_actions(feature.steps)

    # 4. 验证结果
    result = await verify_outcome()

    # 5. 更新状态
    update_feature_status(feature.id, result)
```

### 5.2 启动时验证的重要性

文章强调在**每次会话开始时先验证基础功能**。这是一个关键的最佳实践:

1. **环境可靠性检查**: 确保开发服务器正常运行
2. **防止级联失败**: 基础功能损坏时,新 feature 即使实现正确也会失败
3. **建立信心**: 验证通过为后续工作提供心理安全感

---

## 六、失败模式与解决方案

| 失败模式 | 原因 | 解决方案 |
|----------|------|----------|
| 过早宣布完成 | Agent 缺乏外部验证机制 | Feature 列表 + 自动化测试 |
| 环境状态混乱 | 无状态管理 | Git 提交 + 进度文件 |
| Feature 标记不准确 | 自我评估偏差 | 严格自验证后才标记 passes |
| 花费时间理解应用 | 缺乏快速启动能力 | init.sh 脚本化启动流程 |

---

## 七、技术栈与工具链

| 工具 | 用途 | 选择理由 |
|------|------|----------|
| Claude Agent SDK | 核心 Agent 框架 | 官方支持,深度集成 |
| Puppeteer MCP | 浏览器自动化 | 端到端测试事实标准 |
| Git | 版本控制 | 状态恢复、变更追踪 |
| JSON | 数据格式 | 结构化、可验证 |

---

## 八、个人深度思考

### 8.1 这个框架解决的核心问题是什么?

我认为这个框架本质上是将 **"Agent 的自主性"与"人类的控制力"** 进行了平衡:

- **Agent 端**: 拥有关于"如何做"的完整自主权
- **人类端**: 掌控"做什么"和"做到什么程度"

### 8.2 这个方案的局限性

1. **Feature 列表的构建**: 需要人工预先定义所有 feature,这本身就是一项复杂工作
2. **测试依赖**: 高度依赖自动化测试的准确性,测试本身可能成为瓶颈
3. **并发场景**: 目前方案是串行的,不适合需要并行开发的场景

### 8.3 扩展方向(个人建议)

1. **多 Agent 协作**:
   - 编码 Agent: 负责实现
   - 测试 Agent: 负责验证
   - QA Agent: 负责审查
   - 清理 Agent: 负责代码优化

2. **智能 Feature 分解**:
   - 使用 AI 辅助将宏大目标分解为可管理的 feature
   - 动态调整优先级

3. **状态持久化增强**:
   - 除了 git,还可以考虑数据库存储
   - 支持多会话间的状态对比

---

## 九、实践建议

### 9.1 实施路线图

```
第一阶段: 基础设施
├── 创建 init.sh
├── 初始化 git 仓库
└── 建立空的 feature_list.json

第二阶段: 第一个 Feature
├── 编写第一个 feature 的完整描述
├── 实现基本功能
├── 编写自动化测试
└── 验证通过后提交

第三阶段: 迭代完善
├── 持续添加新 feature
├── 优化测试覆盖
└── 改进流程效率
```

### 9.2 关键检查点

在每个会话结束时,Agent 应该:
- [ ] 提交了 git 更改
- [ ] 更新了进度文件
- [ ] 验证了当前功能的正确性
- [ ] 清理了临时文件

---

## 十、总结

Anthropic 的这篇文章提供了一个**工程化**而非**算法化**的解决方案。它的核心洞见是:

> **与其增强 Agent 的能力,不如约束 Agent 的行为。**

通过建立清晰的结构(初始化 Agent)、明确的规则(feature 列表)、可靠的验证(自动化测试),我们将一个"不可预测的 AI"变成了一个"可管理的工程系统"。

这种方法论不仅适用于代码生成,也可以推广到其他长时间运行的 Agent 场景,如:
- 科学研究
- 数据分析
- 金融建模

---

*本文为个人学习笔记,基于 Anthropic 工程博客内容整理,并加入个人理解和思考。*
